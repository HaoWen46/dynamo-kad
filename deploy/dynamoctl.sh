#!/usr/bin/env bash
# dynamoctl.sh -- Cluster management for dynamo-kad on CSIE workstation pool
#
# Usage: dynamoctl.sh <command> [args...]
# Run  : dynamoctl.sh help   for full command list.
#
# Requirements:
#   - SSH access (passwordless recommended) to all NODES in cluster.conf
#   - grpcurl (optional, for health/cluster-view; falls back to TCP check)
#   - cargo + Rust toolchain (for build command only)

set -euo pipefail

# ── Paths ────────────────────────────────────────────────────────────────
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
CLUSTER_CONF="${SCRIPT_DIR}/cluster.conf"
PROTO_DIR="${PROJECT_ROOT}/specs/v1"

# ── Colours ──────────────────────────────────────────────────────────────
RED='\033[0;31m'; GREEN='\033[0;32m'; YELLOW='\033[1;33m'
BLUE='\033[0;34m'; CYAN='\033[0;36m'; BOLD='\033[1m'; NC='\033[0m'

log_info()  { echo -e "${GREEN}[INFO]${NC}  $*"; }
log_warn()  { echo -e "${YELLOW}[WARN]${NC}  $*"; }
log_error() { echo -e "${RED}[ERROR]${NC} $*"; }
log_step()  { echo -e "${BLUE}[====]${NC} ${BOLD}$*${NC}"; }

# ── Load cluster config ─────────────────────────────────────────────────
if [[ ! -f "${CLUSTER_CONF}" ]]; then
    log_error "Cluster config not found: ${CLUSTER_CONF}"
    exit 1
fi
# shellcheck source=cluster.conf
source "${CLUSTER_CONF}"

# ── SSH helpers ──────────────────────────────────────────────────────────

# Run a command on a remote node.
# Usage: ssh_node <ip> <command...>
ssh_node() {
    local ip="$1"; shift
    # shellcheck disable=SC2086
    ssh ${SSH_OPTS} "${SSH_USER}@${ip}" "$@"
}

# Build the seed list string for YAML configs.
build_seed_list() {
    local seeds=""
    for idx in "${SEED_INDICES[@]}"; do
        seeds="${seeds}  - \"${NODES[$idx]}:${GRPC_PORT}\""$'\n'
    done
    echo "${seeds}"
}

# ── Subcommands ──────────────────────────────────────────────────────────

# ---------- gen-config ----------
cmd_gen_config() {
    log_step "Generating configs for ${#NODES[@]} nodes"

    local seed_yaml
    seed_yaml="$(build_seed_list)"

    for ip in "${NODES[@]}"; do
        local config_content
        config_content="$(cat <<ENDYAML
# dynamo-kad node config — auto-generated by dynamoctl
# Node: ${ip}  Generated: $(date -u +"%Y-%m-%dT%H:%M:%SZ")

listen: "${ip}:${GRPC_PORT}"

seeds:
${seed_yaml}
metrics_port: ${METRICS_PORT}

kademlia:
  k: ${KAD_K}
  alpha: ${KAD_ALPHA}
  rpc_timeout_ms: ${KAD_RPC_TIMEOUT_MS}
  refresh_interval_secs: ${KAD_REFRESH_INTERVAL_SECS}
  max_records: ${KAD_MAX_RECORDS}

kv:
  n: ${KV_N}
  r: ${KV_R}
  w: ${KV_W}
  read_repair: ${KV_READ_REPAIR}
  hinted_handoff: ${KV_HINTED_HANDOFF}
  hint_delivery_interval_secs: ${KV_HINT_DELIVERY_INTERVAL_SECS}
  max_hints_per_cycle: ${KV_MAX_HINTS_PER_CYCLE}

storage:
  data_dir: "${REMOTE_DATA}"
  fsync: ${STORAGE_FSYNC}
ENDYAML
)"
        ssh_node "${ip}" "mkdir -p ${REMOTE_BIN} ${REMOTE_CONFIG} ${REMOTE_DATA} ${REMOTE_LOG}"
        echo "${config_content}" | ssh_node "${ip}" "cat > ${REMOTE_CONFIG}/node.yaml"
        log_info "${ip}  config written"
    done
    log_info "All configs generated and distributed."
}

# ---------- gen-config-local (for dry-run / testing) ----------
cmd_gen_config_local() {
    local out_dir="${1:-${SCRIPT_DIR}/generated}"
    mkdir -p "${out_dir}"
    log_step "Generating configs locally into ${out_dir}"

    local seed_yaml
    seed_yaml="$(build_seed_list)"

    for ip in "${NODES[@]}"; do
        local config_content
        config_content="$(cat <<ENDYAML
# dynamo-kad node config — auto-generated by dynamoctl
# Node: ${ip}  Generated: $(date -u +"%Y-%m-%dT%H:%M:%SZ")

listen: "${ip}:${GRPC_PORT}"

seeds:
${seed_yaml}
metrics_port: ${METRICS_PORT}

kademlia:
  k: ${KAD_K}
  alpha: ${KAD_ALPHA}
  rpc_timeout_ms: ${KAD_RPC_TIMEOUT_MS}
  refresh_interval_secs: ${KAD_REFRESH_INTERVAL_SECS}
  max_records: ${KAD_MAX_RECORDS}

kv:
  n: ${KV_N}
  r: ${KV_R}
  w: ${KV_W}
  read_repair: ${KV_READ_REPAIR}
  hinted_handoff: ${KV_HINTED_HANDOFF}
  hint_delivery_interval_secs: ${KV_HINT_DELIVERY_INTERVAL_SECS}
  max_hints_per_cycle: ${KV_MAX_HINTS_PER_CYCLE}

storage:
  data_dir: "${REMOTE_DATA}"
  fsync: ${STORAGE_FSYNC}
ENDYAML
)"
        local filename
        filename="node-${ip##*.}.yaml"  # e.g. node-182.yaml
        echo "${config_content}" > "${out_dir}/${filename}"
        log_info "  ${out_dir}/${filename}"
    done
    log_info "Done.  ${#NODES[@]} configs in ${out_dir}/"
}

# ---------- build ----------
cmd_build() {
    log_step "Building dynamo-node (release) locally"
    cd "${PROJECT_ROOT}"
    cargo build --release -p dynamo-node 2>&1

    local binary="${PROJECT_ROOT}/target/release/dynamo-node"
    if [[ ! -f "${binary}" ]]; then
        log_error "Binary not found at ${binary}"
        exit 1
    fi
    log_info "Build OK  $(du -h "${binary}" | cut -f1)  ${binary}"
}

# ---------- build-remote ----------
# Build on a remote CSIE node (needed when running from macOS).
# Uses the NFS-shared project directory so the binary is visible to all nodes.
cmd_build_remote() {
    local build_node="${1:-${NODES[0]}}"
    local remote_proj="${REMOTE_PROJECT}"

    # Auto-detect: if REMOTE_PROJECT is empty, ask the build node for the path
    if [[ -z "${remote_proj}" ]]; then
        # Assume same relative path under $HOME on remote
        local rel_path="${PROJECT_ROOT/#$HOME/}"
        remote_proj="$(ssh_node "${build_node}" "echo \$HOME")${rel_path}"
        log_info "Auto-detected remote project path: ${remote_proj}"
    fi

    log_step "Building on ${build_node} (remote)"
    ssh_node "${build_node}" "
        source \$HOME/.cargo/env 2>/dev/null || true
        cd '${remote_proj}' || { echo 'ERROR: project dir not found'; exit 1; }
        cargo build --release -p dynamo-node 2>&1
    "

    # Verify binary exists via the same remote path
    local remote_binary="${remote_proj}/target/release/dynamo-node"
    if ! ssh_node "${build_node}" "test -f '${remote_binary}'"; then
        log_error "Binary not found at ${build_node}:${remote_binary}"
        exit 1
    fi

    local size
    size="$(ssh_node "${build_node}" "du -h '${remote_binary}' | cut -f1")"
    log_info "Build OK  ${size}  ${build_node}:${remote_binary}"

    # Store for distribute to pick up
    REMOTE_BINARY="${remote_binary}"
    BUILD_NODE="${build_node}"
}

# ---------- distribute ----------
cmd_distribute() {
    # If REMOTE_BINARY is set (from build-remote), copy from NFS on the
    # remote side.  Otherwise scp from local.
    if [[ -n "${REMOTE_BINARY:-}" ]]; then
        log_step "Distributing binary to ${#NODES[@]} nodes (remote copy from NFS)"
        local pids=() failures=0

        for ip in "${NODES[@]}"; do
            (
                ssh_node "${ip}" "mkdir -p ${REMOTE_BIN} && cp '${REMOTE_BINARY}' ${REMOTE_BIN}/dynamo-node && chmod +x ${REMOTE_BIN}/dynamo-node"
                log_info "${ip}  binary copied (NFS→local)"
            ) &
            pids+=($!)
        done

        for i in "${!pids[@]}"; do
            if ! wait "${pids[$i]}"; then
                log_error "Failed on ${NODES[$i]}"
                ((failures++)) || true
            fi
        done

        if [[ ${failures} -gt 0 ]]; then
            log_error "${failures} node(s) failed"; exit 1
        fi
    else
        local binary="${PROJECT_ROOT}/target/release/dynamo-node"
        if [[ ! -f "${binary}" ]]; then
            log_error "Binary not found. Run '$(basename "$0") build' or 'build-remote' first."
            exit 1
        fi

        log_step "Distributing binary to ${#NODES[@]} nodes (scp from local)"
        local pids=() failures=0

        for ip in "${NODES[@]}"; do
            (
                ssh_node "${ip}" "mkdir -p ${REMOTE_BIN}"
                # shellcheck disable=SC2086
                scp ${SSH_OPTS} -q "${binary}" "${SSH_USER}@${ip}:${REMOTE_BIN}/dynamo-node"
                ssh_node "${ip}" "chmod +x ${REMOTE_BIN}/dynamo-node"
                log_info "${ip}  binary copied (scp)"
            ) &
            pids+=($!)
        done

        for i in "${!pids[@]}"; do
            if ! wait "${pids[$i]}"; then
                log_error "Failed on ${NODES[$i]}"
                ((failures++)) || true
            fi
        done

        if [[ ${failures} -gt 0 ]]; then
            log_error "${failures} node(s) failed"; exit 1
        fi
    fi
    log_info "Distribution complete."
}

# ---------- check-ports ----------
cmd_check_ports() {
    log_step "Checking port availability"
    local failures=0

    for ip in "${NODES[@]}"; do
        local result
        result="$(ssh_node "${ip}" "
            ok=true
            if ss -tlnp 2>/dev/null | grep -qE ':${GRPC_PORT}\b'; then
                echo 'gRPC port ${GRPC_PORT} IN USE'; ok=false
            fi
            if ss -tlnp 2>/dev/null | grep -qE ':${METRICS_PORT}\b'; then
                echo 'metrics port ${METRICS_PORT} IN USE'; ok=false
            fi
            if \$ok; then echo OK; fi
        " 2>&1)" || true

        if [[ "${result}" == "OK" ]]; then
            log_info "${ip}  ports ${GRPC_PORT},${METRICS_PORT} free"
        else
            log_error "${ip}  ${result}"
            ((failures++)) || true
        fi
    done

    if [[ ${failures} -gt 0 ]]; then
        log_error "${failures} node(s) have port conflicts"; exit 1
    fi
    log_info "All ports available."
}

# ---------- start ----------
start_single() {
    local ip="$1"
    # Already running?
    local pid
    pid="$(ssh_node "${ip}" "cat ${REMOTE_BASE}/dynamo-node.pid 2>/dev/null" 2>/dev/null || echo "")"
    if [[ -n "${pid}" ]] && ssh_node "${ip}" "kill -0 ${pid} 2>/dev/null" 2>/dev/null; then
        log_warn "${ip}  already running (PID ${pid})"
        return 0
    fi

    ssh_node "${ip}" "
        mkdir -p ${REMOTE_LOG}
        cd ${REMOTE_BASE}
        RUST_LOG=${RUST_LOG_LEVEL} nohup ${REMOTE_BIN}/dynamo-node ${REMOTE_CONFIG}/node.yaml \
            > ${REMOTE_LOG}/dynamo-node.log 2>&1 &
        echo \$! > ${REMOTE_BASE}/dynamo-node.pid
    "
    log_info "${ip}  started"
}

cmd_start() {
    local target="${1:-all}"

    if [[ "${target}" != "all" ]]; then
        log_step "Starting node ${target}"
        start_single "${target}"
        return
    fi

    log_step "Starting cluster (${#NODES[@]} nodes)"

    # Wave 1: seed nodes
    log_info "Wave 1 — seed nodes"
    for idx in "${SEED_INDICES[@]}"; do
        start_single "${NODES[$idx]}"
    done
    log_info "Waiting 2s for seeds to initialise..."
    sleep 2

    # Wave 2: remaining nodes
    log_info "Wave 2 — remaining nodes"
    for i in "${!NODES[@]}"; do
        local is_seed=false
        for idx in "${SEED_INDICES[@]}"; do
            [[ "$i" -eq "$idx" ]] && { is_seed=true; break; }
        done
        $is_seed || start_single "${NODES[$i]}"
    done

    log_info "Cluster started.  Waiting 5s for bootstrap..."
    sleep 5
}

# ---------- stop ----------
cmd_stop() {
    local target="${1:-all}"

    local nodes_to_stop=()
    if [[ "${target}" == "all" ]]; then
        nodes_to_stop=("${NODES[@]}")
    else
        nodes_to_stop=("${target}")
    fi

    log_step "Stopping ${#nodes_to_stop[@]} node(s)"
    for ip in "${nodes_to_stop[@]}"; do
        local pid
        pid="$(ssh_node "${ip}" "cat ${REMOTE_BASE}/dynamo-node.pid 2>/dev/null" 2>/dev/null || echo "")"
        if [[ -z "${pid}" ]]; then
            log_warn "${ip}  no PID file"
            continue
        fi
        if ssh_node "${ip}" "kill -0 ${pid} 2>/dev/null" 2>/dev/null; then
            # SIGINT for graceful tokio shutdown
            ssh_node "${ip}" "kill -INT ${pid}; rm -f ${REMOTE_BASE}/dynamo-node.pid" 2>/dev/null || true
            log_info "${ip}  stopped (PID ${pid})"
        else
            ssh_node "${ip}" "rm -f ${REMOTE_BASE}/dynamo-node.pid" 2>/dev/null || true
            log_warn "${ip}  PID ${pid} was not running, cleaned up"
        fi
    done
}

# ---------- status ----------
cmd_status() {
    log_step "Cluster status"
    printf "${CYAN}%-18s %-8s %-8s %-12s${NC}\n" "NODE" "PID" "STATE" "UPTIME"
    printf "%-18s %-8s %-8s %-12s\n"              "────" "───" "─────" "──────"

    for ip in "${NODES[@]}"; do
        local pid state uptime_str
        pid="$(ssh_node "${ip}" "cat ${REMOTE_BASE}/dynamo-node.pid 2>/dev/null" 2>/dev/null || echo "")"

        if [[ -z "${pid}" ]]; then
            state="DOWN"; pid="-"; uptime_str="-"
        elif ssh_node "${ip}" "kill -0 ${pid} 2>/dev/null" 2>/dev/null; then
            state="UP"
            uptime_str="$(ssh_node "${ip}" "ps -o etime= -p ${pid} 2>/dev/null" 2>/dev/null | tr -d ' ')" || uptime_str="?"
        else
            state="DEAD"; uptime_str="-"
        fi

        if [[ "${state}" == "UP" ]]; then
            printf "${GREEN}%-18s %-8s %-8s %-12s${NC}\n" "${ip}" "${pid}" "${state}" "${uptime_str}"
        elif [[ "${state}" == "DEAD" ]]; then
            printf "${RED}%-18s %-8s %-8s %-12s${NC}\n"   "${ip}" "${pid}" "${state}" "${uptime_str}"
        else
            printf "%-18s %-8s %-8s %-12s\n"              "${ip}" "${pid}" "${state}" "${uptime_str}"
        fi
    done
}

# ---------- check-conn ----------
# Try bash /dev/tcp first (Linux), fall back to nc (macOS / busybox).
tcp_check() {
    local ip="$1" port="$2"
    if command -v timeout &>/dev/null; then
        timeout 3 bash -c "echo >/dev/tcp/${ip}/${port}" 2>/dev/null
    elif nc -z -w3 "${ip}" "${port}" 2>/dev/null; then
        return 0
    else
        return 1
    fi
}

cmd_check_connectivity() {
    log_step "TCP connectivity on port ${GRPC_PORT}"
    local ok=0 fail=0

    for ip in "${NODES[@]}"; do
        if tcp_check "${ip}" "${GRPC_PORT}"; then
            log_info "${ip}:${GRPC_PORT}  reachable"
            ((ok++)) || true
        else
            log_error "${ip}:${GRPC_PORT}  UNREACHABLE"
            ((fail++)) || true
        fi
    done
    echo ""
    log_info "Reachable: ${ok}  Unreachable: ${fail}"
    [[ ${fail} -eq 0 ]]
}

# ---------- health ----------
cmd_health() {
    log_step "Health check (Admin.Health RPC)"

    if ! command -v grpcurl &>/dev/null; then
        log_warn "grpcurl not found — falling back to TCP check"
        cmd_check_connectivity
        return
    fi

    local healthy=0 unhealthy=0
    printf "${CYAN}%-18s %-8s %-20s %-10s${NC}\n" "NODE" "STATUS" "NODE_ID" "UPTIME(s)"
    printf "%-18s %-8s %-20s %-10s\n"              "────" "──────" "───────" "─────────"

    for ip in "${NODES[@]}"; do
        local result
        result="$(grpcurl -plaintext \
            -import-path "${PROTO_DIR}" \
            -proto admin.proto \
            "${ip}:${GRPC_PORT}" \
            dynamo.admin.AdminService/Health 2>&1)" || true

        if echo "${result}" | grep -q '"healthy": true'; then
            local node_id uptime_secs
            node_id="$(echo "${result}" | grep -o '"nodeId": "[^"]*"' | head -1 | cut -d'"' -f4 | cut -c1-16)"
            uptime_secs="$(echo "${result}" | grep -oE '"uptimeSecs": "?[0-9]+"?' | head -1 | grep -oE '[0-9]+')"
            printf "${GREEN}%-18s %-8s %-20s %-10s${NC}\n" "${ip}" "OK" "${node_id}…" "${uptime_secs:-?}"
            ((healthy++)) || true
        else
            printf "${RED}%-18s %-8s %-20s %-10s${NC}\n" "${ip}" "FAIL" "-" "-"
            ((unhealthy++)) || true
        fi
    done

    echo ""
    log_info "Healthy: ${healthy}  Unhealthy: ${unhealthy}  Total: ${#NODES[@]}"
    [[ ${unhealthy} -eq 0 ]]
}

# ---------- cluster-view ----------
cmd_cluster_view() {
    local target="${1:-${NODES[0]}}"
    log_step "Cluster view from ${target}"

    if ! command -v grpcurl &>/dev/null; then
        log_error "grpcurl required for cluster-view"; exit 1
    fi

    grpcurl -plaintext \
        -import-path "${PROTO_DIR}" \
        -proto admin.proto \
        "${target}:${GRPC_PORT}" \
        dynamo.admin.AdminService/ClusterView
}

# ---------- stats ----------
cmd_stats() {
    local target="${1:-${NODES[0]}}"
    log_step "Stats from ${target}"

    if ! command -v grpcurl &>/dev/null; then
        log_error "grpcurl required"; exit 1
    fi

    grpcurl -plaintext \
        -import-path "${PROTO_DIR}" \
        -proto admin.proto \
        "${target}:${GRPC_PORT}" \
        dynamo.admin.AdminService/GetStats
}

# ---------- logs ----------
cmd_logs() {
    local ip="${1:?Usage: $(basename "$0") logs <ip> [lines]}"
    local lines="${2:-50}"
    ssh_node "${ip}" "tail -n ${lines} ${REMOTE_LOG}/dynamo-node.log" 2>/dev/null
}

cmd_logs_follow() {
    local ip="${1:?Usage: $(basename "$0") logs-follow <ip>}"
    ssh_node "${ip}" "tail -f ${REMOTE_LOG}/dynamo-node.log"
}

# ---------- metrics ----------
cmd_metrics() {
    local ip="${1:?Usage: $(basename "$0") metrics <ip>}"
    curl -s "http://${ip}:${METRICS_PORT}/metrics"
}

# ---------- clean ----------
cmd_clean() {
    log_step "Cleaning all node data"

    # Safety: refuse if any node is still running
    for ip in "${NODES[@]}"; do
        local pid
        pid="$(ssh_node "${ip}" "cat ${REMOTE_BASE}/dynamo-node.pid 2>/dev/null" 2>/dev/null || echo "")"
        if [[ -n "${pid}" ]] && ssh_node "${ip}" "kill -0 ${pid} 2>/dev/null" 2>/dev/null; then
            log_error "${ip} still running (PID ${pid}).  Stop first."
            exit 1
        fi
    done

    for ip in "${NODES[@]}"; do
        ssh_node "${ip}" "rm -rf ${REMOTE_DATA} ${REMOTE_LOG}/*.log ${REMOTE_BASE}/dynamo-node.pid" 2>/dev/null || true
        log_info "${ip}  cleaned"
    done
}

# ---------- nuke ----------
cmd_nuke() {
    log_step "Nuking ${REMOTE_BASE} on ALL nodes"
    echo -e "${RED}This will delete EVERYTHING under ${REMOTE_BASE} on all ${#NODES[@]} nodes.${NC}"
    read -rp "Type YES to confirm: " confirm
    if [[ "${confirm}" != "YES" ]]; then
        log_info "Aborted."; return
    fi

    cmd_stop all 2>/dev/null || true
    for ip in "${NODES[@]}"; do
        ssh_node "${ip}" "rm -rf ${REMOTE_BASE}" 2>/dev/null || true
        log_info "${ip}  nuked"
    done
}

# ---------- deploy (full pipeline) ----------
cmd_deploy() {
    cmd_build
    cmd_distribute
    cmd_gen_config
    cmd_check_ports
    cmd_start all
    cmd_health
}

# deploy-remote: same pipeline but builds on a CSIE node (for macOS → Linux).
cmd_deploy_remote() {
    cmd_build_remote "${1:-${NODES[0]}}"
    cmd_distribute
    cmd_gen_config
    cmd_check_ports
    cmd_start all
    cmd_health
}

# ── Usage / dispatch ─────────────────────────────────────────────────────
usage() {
    cat <<EOF
${BOLD}dynamoctl.sh${NC} — Cluster management for dynamo-kad

${CYAN}LIFECYCLE${NC}
  deploy                Full pipeline: build → distribute → config → start → health
  deploy-remote [node]  Same but builds on a CSIE node (run from macOS)
  build                 Build release binary locally (cargo build --release)
  build-remote [node]   Build on a remote node via SSH (default: first node)
  distribute            Copy binary to all nodes (/tmp2/dynamo-kad/bin/)
  gen-config            Generate & distribute per-node YAML configs
  gen-config-local [d]  Generate configs locally (for review/dry-run)
  start [ip]            Start cluster (seeds first) or a single node
  stop  [ip]            Stop cluster or a single node (SIGINT graceful)
  clean                 Remove data/logs (requires stopped cluster)
  nuke                  Delete everything under /tmp2/dynamo-kad (asks confirmation)

${CYAN}OBSERVABILITY${NC}
  status                Process status on all nodes
  health                gRPC Admin.Health check on all nodes
  check-ports           Verify gRPC/metrics ports are free
  check-conn            TCP connectivity test on all nodes
  cluster-view [ip]     Kademlia routing table from a node (default: first node)
  stats [ip]            Get stats from a node
  logs <ip> [n]         Show last n lines of a node's log (default: 50)
  logs-follow <ip>      tail -f a node's log
  metrics <ip>          Fetch Prometheus metrics

${CYAN}EXAMPLES${NC}
  ./dynamoctl.sh deploy                  # full deployment (local build)
  ./dynamoctl.sh deploy-remote           # full deployment (build on CSIE node)
  ./dynamoctl.sh gen-config-local        # preview configs locally
  ./dynamoctl.sh start                   # start all nodes
  ./dynamoctl.sh stop 140.112.30.185     # stop one node
  ./dynamoctl.sh health                  # verify cluster
  ./dynamoctl.sh logs 140.112.30.182 100 # read a node's log
EOF
}

case "${1:-help}" in
    deploy)           cmd_deploy ;;
    deploy-remote)    cmd_deploy_remote "${2:-}" ;;
    build)            cmd_build ;;
    build-remote)     cmd_build_remote "${2:-}" ;;
    distribute)       cmd_distribute ;;
    gen-config)       cmd_gen_config ;;
    gen-config-local) cmd_gen_config_local "${2:-}" ;;
    check-ports)      cmd_check_ports ;;
    start)            cmd_start "${2:-all}" ;;
    stop)             cmd_stop  "${2:-all}" ;;
    status)           cmd_status ;;
    health)           cmd_health ;;
    check-conn)       cmd_check_connectivity ;;
    cluster-view)     cmd_cluster_view "${2:-}" ;;
    stats)            cmd_stats "${2:-}" ;;
    logs)             cmd_logs "${2:-}" "${3:-50}" ;;
    logs-follow)      cmd_logs_follow "${2:-}" ;;
    metrics)          cmd_metrics "${2:-}" ;;
    clean)            cmd_clean ;;
    nuke)             cmd_nuke ;;
    help|--help|-h)   usage ;;
    *)
        log_error "Unknown command: $1"
        usage
        exit 1
        ;;
esac
